<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Pierre  Marza


  | Artificial Intelligence & Data Analysis

</title>
<meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<!-- <link rel="stylesheet" href="https://gitcdn.xyz/repo/jwarby/jekyll-pygments-themes/master/github.css" /> -->
<!-- <link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />  -->

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22></text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/teaching/3_teaching_rnn/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>






    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


    <script src="/assets/js/distillpub/template.v2.js"></script>
    <script src="/assets/js/distillpub/transforms.v2.js"></script>
    <script src="/assets/js/distillpub/overrides.js"></script>
    
    <style type="text/css">
      .fake-img {
  background: #bbb;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
  margin-bottom: 12px;
} .fake-img p {
  font-family: monospace;
  color: white;
  text-align: left;
  margin: 12px 0;
  text-align: center;
  font-size: 16px;
}

    </style>
    
  </head>

  <d-front-matter>
    <script async type="text/json">{
      "title": "Artificial Intelligence & Data Analysis",
      "description": "Recurrent Neural Networks",
      "published": "February 5, 2024",
      "authors": [
        
        {
          "author": "Pierre Marza",
          "authorURL": "https://pierremarza.github.io/",
          "affiliations": [
            {
              "name": "INSA, Lyon",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script>
  </d-front-matter>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="/">
       <span class="font-weight-bold">Pierre</span>   Marza
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              About
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/challenges/">
                Challenges
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/projects/">
                Projects
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                Research
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/teaching/">
                Teaching
                
              </a>
          </li>
          
          
          
          
          
          
          
          
          
            <div class = "toggle-container">
              <a id = "light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="post distill">

      <d-title>
        <h1>Artificial Intelligence & Data Analysis</h1>
        <p>Recurrent Neural Networks</p>
      </d-title>

      <d-byline></d-byline>

      <d-article>
        <h1 id="1-lecture">1. Lecture</h1>
<p>The lecture slides are available <a href="https://pierremarza.github.io/teaching/lyon1_m1_deep_learning_rnn.pdf">here</a>.</p>

<h1 id="2-practical">2. Practical</h1>
<h2 id="context">Context</h2>
<p>The goals of this session are to practice with <strong>implementing a Recurrent Neural Network</strong>, <strong>understanding the involved computations</strong>, and more generally, to <strong>build a full Deep Learning pipeline in PyTorch</strong> to train a model on a given dataset.</p>

<p>This practical session is about <strong>training a model to predict the country of origin of an input name</strong>. More specifically, you will be working here with sequences of letters (each letter will be a token): you will have to implement a RNN that takes one letter of the name at a time as input and finally predicts the origin of the entire name.</p>

<p><img src="/assets/img/epita_tp_rnn/fig_tp_rnn.png" width="700" /></p>

<h2 id="installation">Installation</h2>
<p>We will be coding with <strong>Python3</strong> and will use the <strong>Pytorch</strong> library.</p>

<p>To install Pytorch on your local machine, follow this <a href="https://pytorch.org/get-started/locally/">link</a></p>

<h2 id="recurrent-neural-networks">Recurrent Neural Networks</h2>
<p>Recurrent Neural networks (RNNs) are powerful neural models that extract information from sequential data. You can refer to your <a href="https://pierremarza.github.io/teaching/lyon1_m1_deep_learning_rnn.pdf">lecture</a> for more information about RNNs, as well as many great online resources.</p>

<h2 id="the-dataset">The dataset</h2>
<p>The dataset you will use can be downloaded <a href="https://download.pytorch.org/tutorial/data.zip">here</a>. It is composed of <strong>pairs of names and associated countries of origin</strong>. We are interested in the <em>name</em> folder (you can discard the <em>eng-fra.txt</em> file). Inside this folder, you will find 18 files named as <em>origin.txt</em> containing a list of names with the said origin.</p>

<h2 id="data-pre-processing">Data pre-processing</h2>
<p>When dealing with text data, some pre-processing is usually necessary. The following code does eveything you need. After executing it, you will end up with 3 lists: <em>train_samples</em>, <em>val_samples</em> and <em>test_samples</em> that correspond to our 3 data sets. Each element in a list will be a dictionary with 2 keys: <em>name</em>, i.e. a given input name (sequence of characters) and <em>label</em> which is the id (from 0 to 17) associated with the country of origin of the name. This code also computes the length of the longuest name in the data: this can be useful to pad input sequences (names) of different lengths so that we can build training batches out of them. Some of the defined functions are not directly used in this code snippet (<em>letterToIndex</em>, <em>letterToTensor</em>, <em>lineToTensor</em>) but will be useful later to implement your <em>Dataset</em> class (see next section). These functions build a tensor by encoding each character in the name as a one-hot vector (vector of zeros and only a one at the id position associated to the letter) that thus contains as many elements as existing letters.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">io</span> <span class="kn">import</span> <span class="nb">open</span>
<span class="kn">import</span> <span class="n">glob</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">os</span>
<span class="kn">import</span> <span class="n">unicodedata</span>
<span class="kn">import</span> <span class="n">random</span>
<span class="kn">import</span> <span class="n">string</span>
<span class="kn">import</span> <span class="n">torch</span>

<span class="k">def</span> <span class="nf">findFiles</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">glob</span><span class="p">.</span><span class="nf">glob</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>


<span class="c1"># Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427
</span><span class="k">def</span> <span class="nf">unicodeToAscii</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">all_letters</span><span class="p">):</span>
    <span class="k">return</span> <span class="sh">""</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span>
        <span class="n">c</span>
        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">unicodedata</span><span class="p">.</span><span class="nf">normalize</span><span class="p">(</span><span class="sh">"</span><span class="s">NFD</span><span class="sh">"</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">unicodedata</span><span class="p">.</span><span class="nf">category</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="o">!=</span> <span class="sh">"</span><span class="s">Mn</span><span class="sh">"</span> <span class="ow">and</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">all_letters</span>
    <span class="p">)</span>


<span class="c1"># Read a file and split into lines
</span><span class="k">def</span> <span class="nf">readLines</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">all_letters</span><span class="p">):</span>
    <span class="n">lines</span> <span class="o">=</span> <span class="nf">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="sh">"</span><span class="s">utf-8</span><span class="sh">"</span><span class="p">).</span><span class="nf">read</span><span class="p">().</span><span class="nf">strip</span><span class="p">().</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="sh">"</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="nf">unicodeToAscii</span><span class="p">(</span><span class="n">line</span><span class="p">,</span> <span class="n">all_letters</span><span class="p">)</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">]</span>


<span class="c1"># Find letter index from all_letters, e.g. "a" = 0
</span><span class="k">def</span> <span class="nf">letterToIndex</span><span class="p">(</span><span class="n">letter</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">all_letters</span><span class="p">.</span><span class="nf">find</span><span class="p">(</span><span class="n">letter</span><span class="p">)</span>


<span class="c1"># Just for demonstration, turn a letter into a &lt;1 x n_letters&gt; Tensor
</span><span class="k">def</span> <span class="nf">letterToTensor</span><span class="p">(</span><span class="n">letter</span><span class="p">):</span>
    <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_letters</span><span class="p">)</span>
    <span class="n">tensor</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="nf">letterToIndex</span><span class="p">(</span><span class="n">letter</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">tensor</span>


<span class="c1"># Turn a line into a &lt;line_length x 1 x n_letters&gt;,
# or an array of one-hot letter vectors
</span><span class="k">def</span> <span class="nf">lineToTensor</span><span class="p">(</span><span class="n">line</span><span class="p">):</span>
    <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">line</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_letters</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">li</span><span class="p">,</span> <span class="n">letter</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">line</span><span class="p">):</span>
        <span class="n">tensor</span><span class="p">[</span><span class="n">li</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="nf">letterToIndex</span><span class="p">(</span><span class="n">letter</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">tensor</span>


<span class="c1"># Listing all possible letters/characters
</span><span class="n">all_letters</span> <span class="o">=</span> <span class="n">string</span><span class="p">.</span><span class="n">ascii_letters</span> <span class="o">+</span> <span class="sh">"</span><span class="s"> .,;</span><span class="sh">'"</span>
<span class="n">n_letters</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">all_letters</span><span class="p">)</span>

<span class="c1"># Creating a list of samples for each data set (train, val, test)
# One sample will be a dictionary with 2 keys:
# * "name": the input name which is a sequence of characters (e.g. 'Adam')
# * "label": the origin country of the name (this will be an integer from 0 to 17 as there are 18 countries)
# We will also compute the length of the longuest name in the while data (to be able to pad sequences later when
# building training batches).
</span><span class="n">train_samples</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">val_samples</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">test_samples</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">max_line_len</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">label_id</span><span class="p">,</span> <span class="n">filename</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="nf">findFiles</span><span class="p">(</span><span class="sh">"</span><span class="s">data/names/*.txt</span><span class="sh">"</span><span class="p">)):</span>
    <span class="n">lines</span> <span class="o">=</span> <span class="nf">readLines</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">all_letters</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">:</span>
        <span class="n">max_line_len</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="n">max_line_len</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">line</span><span class="p">))</span>

    <span class="c1"># Computing the size of train, val, test sets
</span>    <span class="n">all_indices</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">lines</span><span class="p">)).</span><span class="nf">tolist</span><span class="p">()</span>
    <span class="n">train_length</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="mf">0.75</span> <span class="o">*</span> <span class="nf">len</span><span class="p">(</span><span class="n">lines</span><span class="p">))</span>
    <span class="n">val_length</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="mf">0.10</span> <span class="o">*</span> <span class="nf">len</span><span class="p">(</span><span class="n">lines</span><span class="p">))</span>
    <span class="n">test_length</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">lines</span><span class="p">)</span> <span class="o">-</span> <span class="n">train_length</span> <span class="o">-</span> <span class="n">val_length</span>

    <span class="c1"># Sampling data to fill our 3 sets
</span>    <span class="n">train_indices</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="nf">sample</span><span class="p">(</span><span class="n">all_indices</span><span class="p">,</span> <span class="n">train_length</span><span class="p">)</span>
    <span class="n">val_test_indices</span> <span class="o">=</span> <span class="p">[</span><span class="n">index</span> <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">all_indices</span> <span class="k">if</span> <span class="n">index</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">train_indices</span><span class="p">]</span>
    <span class="n">val_indices</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="nf">sample</span><span class="p">(</span><span class="n">val_test_indices</span><span class="p">,</span> <span class="n">val_length</span><span class="p">)</span>
    <span class="n">test_indices</span> <span class="o">=</span> <span class="p">[</span><span class="n">index</span> <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">val_test_indices</span> <span class="k">if</span> <span class="n">index</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">val_indices</span><span class="p">]</span>
    <span class="k">assert</span> <span class="nf">len</span><span class="p">(</span><span class="n">train_indices</span><span class="p">)</span> <span class="o">==</span> <span class="n">train_length</span>
    <span class="k">assert</span> <span class="nf">len</span><span class="p">(</span><span class="n">val_indices</span><span class="p">)</span> <span class="o">==</span> <span class="n">val_length</span>
    <span class="k">assert</span> <span class="nf">len</span><span class="p">(</span><span class="n">test_indices</span><span class="p">)</span> <span class="o">==</span> <span class="n">test_length</span>

    <span class="n">lines</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">lines</span><span class="p">)</span>
    <span class="n">train_samples</span><span class="p">.</span><span class="nf">extend</span><span class="p">(</span>
        <span class="p">[{</span><span class="sh">"</span><span class="s">name</span><span class="sh">"</span><span class="p">:</span> <span class="n">line</span><span class="p">,</span> <span class="sh">"</span><span class="s">label</span><span class="sh">"</span><span class="p">:</span> <span class="n">label_id</span><span class="p">}</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">[</span><span class="n">train_indices</span><span class="p">]]</span>
    <span class="p">)</span>
    <span class="n">val_samples</span><span class="p">.</span><span class="nf">extend</span><span class="p">(</span>
        <span class="p">[{</span><span class="sh">"</span><span class="s">name</span><span class="sh">"</span><span class="p">:</span> <span class="n">line</span><span class="p">,</span> <span class="sh">"</span><span class="s">label</span><span class="sh">"</span><span class="p">:</span> <span class="n">label_id</span><span class="p">}</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">[</span><span class="n">val_indices</span><span class="p">]]</span>
    <span class="p">)</span>
    <span class="n">test_samples</span><span class="p">.</span><span class="nf">extend</span><span class="p">(</span>
        <span class="p">[{</span><span class="sh">"</span><span class="s">name</span><span class="sh">"</span><span class="p">:</span> <span class="n">line</span><span class="p">,</span> <span class="sh">"</span><span class="s">label</span><span class="sh">"</span><span class="p">:</span> <span class="n">label_id</span><span class="p">}</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">[</span><span class="n">test_indices</span><span class="p">]]</span>
    <span class="p">)</span>
</code></pre></div></div>

<h2 id="building-your-dataset">Building your dataset</h2>
<p>An important class in Pytorch is the <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset"><strong>Dataset</strong></a> class. In the previous CNN practical, you didn’t have to worry about this step. But here, you must create your class inheriting from <strong>torch.utils.data.Dataset</strong> and write your custom <em><strong>getitem</strong>()</em> and <em><strong>len</strong>()</em> methods. <em><strong>len</strong>()</em> should return the length of your dataset and <em><strong>getitem</strong>()</em> should return a dataset element given its index as input. See the code snippet below to have the structure of the class to implement.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span> 

<span class="k">class</span> <span class="nc">CustomDataset</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="c1"># TODO: Initialize here what you will need in the other methods.
</span>        <span class="k">pass</span>
    
    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="mi">0</span> <span class="c1"># TODO: modify this method to return the length 
</span>                 <span class="c1"># of your dataset (i.e. number of elements inside).
</span>    
    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{}</span> <span class="c1"># TODO: return a dict with keys and values that 
</span>                  <span class="c1"># contain information from the element at specified
</span>                  <span class="c1"># index in the dataset.
</span></code></pre></div></div>

<details>
  <summary><strong>A solution</strong></summary>
  <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>

<span class="k">class</span> <span class="nc">CustomDataset</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">samples</span><span class="p">,</span> <span class="n">max_line_len</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">samples</span> <span class="o">=</span> <span class="n">samples</span>
        <span class="n">self</span><span class="p">.</span><span class="n">max_line_len</span> <span class="o">=</span> <span class="n">max_line_len</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">samples</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="n">sample_dict</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">samples</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>

        <span class="n">name</span> <span class="o">=</span> <span class="nf">lineToTensor</span><span class="p">(</span><span class="n">sample_dict</span><span class="p">[</span><span class="sh">"</span><span class="s">name</span><span class="sh">"</span><span class="p">])</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">self</span><span class="p">.</span><span class="n">max_line_len</span><span class="p">))</span>
        <span class="n">mask</span><span class="p">[:</span> <span class="n">name</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">name</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">name</span><span class="p">,</span>
                <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">max_line_len</span> <span class="o">-</span> <span class="n">name</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">name</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">name</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
                <span class="p">),</span>
            <span class="p">],</span>
            <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">label</span> <span class="o">=</span> <span class="n">sample_dict</span><span class="p">[</span><span class="sh">"</span><span class="s">label</span><span class="sh">"</span><span class="p">]</span>
        <span class="n">label</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nc">Tensor</span><span class="p">([</span><span class="n">label</span><span class="p">])</span>
        <span class="k">return</span> <span class="p">{</span><span class="sh">"</span><span class="s">name</span><span class="sh">"</span><span class="p">:</span> <span class="n">name</span><span class="p">,</span> <span class="sh">"</span><span class="s">label</span><span class="sh">"</span><span class="p">:</span> <span class="n">label</span><span class="p">,</span> <span class="sh">"</span><span class="s">mask</span><span class="sh">"</span><span class="p">:</span> <span class="n">mask</span><span class="p">}</span>
</code></pre></div>  </div>
</details>
<p><br />
</p>

<h2 id="data-loading-and-visualisation">Data loading and visualisation</h2>
<p>It is important to visualise the data you will be working on. Moreover, when training and evaluating your model, you will need to load data from your training, validation and test sets respectively. To do so, we will use the <a href="https://pytorch.org/tutorials/beginner/basics/data_tutorial.html"><strong>DataLoader</strong></a> class from <a href="https://pytorch.org/docs/stable/data.html"><strong>torch.utils.data</strong></a>.</p>

<p>Start by <strong>implementing 3 dataloaders</strong> for your training, validation and test sets.</p>

<details>
  <summary><strong>A solution</strong></summary>
  <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_dataset</span> <span class="o">=</span> <span class="nc">CustomDataset</span><span class="p">(</span><span class="n">train_samples</span><span class="p">,</span> <span class="n">max_line_len</span><span class="p">)</span>
<span class="n">val_dataset</span> <span class="o">=</span> <span class="nc">CustomDataset</span><span class="p">(</span><span class="n">val_samples</span><span class="p">,</span> <span class="n">max_line_len</span><span class="p">)</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="nc">CustomDataset</span><span class="p">(</span><span class="n">test_samples</span><span class="p">,</span> <span class="n">max_line_len</span><span class="p">)</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="nc">DataLoader</span><span class="p">(</span>
    <span class="n">train_dataset</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">val_dataloader</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="nc">DataLoader</span><span class="p">(</span>
    <span class="n">val_dataset</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">test_dataloader</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="nc">DataLoader</span><span class="p">(</span>
    <span class="n">test_dataset</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
<span class="p">)</span>
</code></pre></div>  </div>
</details>
<p><br />
</p>

<h2 id="designing-a-recurrent-neural-network">Designing a Recurrent Neural Network</h2>
<p>It is now time to build a RNN from scratch! Write a class inheriting from <a href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html"><strong>torch.nn.Module</strong></a>. Be careful of the dimensions of input tensors and the dimensions of your desired output. For now, <strong>you cannot use any other layer than</strong> <a href="https://pytorch.org/docs/stable/generated/torch.nn.Linear.html"><strong>nn.Linear</strong></a>. The goal here is to <strong>implement vanilla recurrent layers from scratch</strong> that take a tensor as input and maintain a hidden vector memory.</p>

<details>
  <summary><strong>A solution</strong></summary>
  <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>

<span class="k">class</span> <span class="nc">RNN</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">RNN</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="n">self</span><span class="p">.</span><span class="n">i2h</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">input_size</span> <span class="o">+</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">h2o</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hidden</span><span class="p">):</span>
        <span class="n">combined</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="nb">input</span><span class="p">,</span> <span class="n">hidden</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">i2h</span><span class="p">(</span><span class="n">combined</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">h2o</span><span class="p">(</span><span class="n">hidden</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span>

    <span class="k">def</span> <span class="nf">initHidden</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">hidden_size</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="nc">RNN</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="mi">57</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="mi">57</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
</code></pre></div>  </div>
</details>
<p><br />
</p>

<h2 id="loss-function-and-optimizer">Loss function and optimizer</h2>
<p>The next step is to define a <a href="https://pytorch.org/docs/stable/nn.html#loss-functions"><strong>loss function</strong></a> that is suited to the problem. Then you have to choose an <a href="https://pytorch.org/docs/stable/optim.html"><strong>optimizer</strong></a>. You are encouraged to try different ones to compare them. You can also study the impact of different hyperparameters of the optimizer (learning rate, momentum, etc.)</p>

<details>
  <summary><strong>A solution</strong></summary>
  <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch.optim</span> <span class="k">as</span> <span class="n">optim</span>

<span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
</code></pre></div>  </div>
</details>
<p><br />
</p>

<h2 id="training-loop">Training loop</h2>
<p>It is now to time to write the code for <strong>training and validating your model</strong>. You must iterate through your training data using your dataloader, and compute forward and backward passes on given data batches.
Don’t forget to log your training as well as validation losses (the latter is mainly used to tune hyperparameters).</p>

<p><strong>Be careful: Unlike for CNNs in the previous practical session, the forward pass here will be iterative as you RNN will take as input one character at a time! You need to propagate you hidden state/memory along time.</strong></p>

<details>
  <summary><strong>A solution</strong></summary>
  <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="k">def</span> <span class="nf">forward_pass</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="n">out</span> <span class="o">=</span> <span class="p">[</span><span class="bp">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">name</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">hidden</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">name</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">57</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">name</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
        <span class="n">character</span> <span class="o">=</span> <span class="n">name</span><span class="p">[:,</span> <span class="n">i</span><span class="p">].</span><span class="nf">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">out_</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">character</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">batch_id</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">name</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="k">if</span> <span class="n">mask</span><span class="p">[</span><span class="n">batch_id</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">out</span><span class="p">[</span><span class="n">batch_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">out_</span><span class="p">[</span><span class="n">batch_id</span><span class="p">].</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">out</span>


<span class="k">def</span> <span class="nf">train_val</span><span class="p">(</span><span class="n">run_type</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
    <span class="n">tot_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">tot_acc</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">mb_idx</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nf">tqdm</span><span class="p">(</span><span class="nf">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)):</span>
        <span class="n">name</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="sh">"</span><span class="s">name</span><span class="sh">"</span><span class="p">]</span>
        <span class="n">label</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="sh">"</span><span class="s">label</span><span class="sh">"</span><span class="p">].</span><span class="nf">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">).</span><span class="nf">long</span><span class="p">()</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="sh">"</span><span class="s">mask</span><span class="sh">"</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">run_type</span> <span class="o">==</span> <span class="sh">"</span><span class="s">train</span><span class="sh">"</span><span class="p">:</span>
            <span class="c1"># zero the parameter gradients
</span>            <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>

        <span class="c1"># Forward pass
</span>        <span class="k">if</span> <span class="n">run_type</span> <span class="o">==</span> <span class="sh">"</span><span class="s">train</span><span class="sh">"</span><span class="p">:</span>
            <span class="n">out</span> <span class="o">=</span> <span class="nf">forward_pass</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">run_type</span> <span class="o">==</span> <span class="sh">"</span><span class="s">val</span><span class="sh">"</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
                <span class="n">out</span> <span class="o">=</span> <span class="nf">forward_pass</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>

        <span class="c1"># Compute loss
</span>        <span class="n">loss</span> <span class="o">=</span> <span class="nf">criterion</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">run_type</span> <span class="o">==</span> <span class="sh">"</span><span class="s">train</span><span class="sh">"</span><span class="p">:</span>
            <span class="c1"># Compute gradients
</span>            <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>

            <span class="c1"># Backward pass - model update
</span>            <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>

        <span class="c1"># Logging
</span>        <span class="n">tot_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span>
        <span class="n">acc</span> <span class="o">=</span> <span class="p">(</span><span class="n">out</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">label</span><span class="p">).</span><span class="nf">tolist</span><span class="p">()</span>
        <span class="n">tot_acc</span><span class="p">.</span><span class="nf">extend</span><span class="p">(</span><span class="n">acc</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tot_loss</span><span class="p">,</span> <span class="n">tot_acc</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span>


<span class="n">epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="c1"># Training
</span>    <span class="n">epoch_loss</span><span class="p">,</span> <span class="n">epoch_acc</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">train_dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span> <span class="o">=</span> <span class="nf">train_val</span><span class="p">(</span>
        <span class="sh">"</span><span class="s">train</span><span class="sh">"</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">train_dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span>
    <span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span>
        <span class="sa">f</span><span class="sh">"</span><span class="s">Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="n">epoch_loss</span><span class="o">/</span><span class="nf">len</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">)</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">epoch_acc</span><span class="p">).</span><span class="nf">mean</span><span class="p">()</span><span class="si">}</span><span class="sh">"</span>
    <span class="p">)</span>

    <span class="c1"># Validation
</span>    <span class="n">val_loss</span><span class="p">,</span> <span class="n">val_acc</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">val_dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span> <span class="o">=</span> <span class="nf">train_val</span><span class="p">(</span>
        <span class="sh">"</span><span class="s">val</span><span class="sh">"</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">val_dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span>
    <span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Val: </span><span class="si">{</span><span class="n">val_loss</span><span class="o">/</span><span class="nf">len</span><span class="p">(</span><span class="n">val_dataloader</span><span class="p">)</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">val_acc</span><span class="p">).</span><span class="nf">mean</span><span class="p">()</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div>  </div>
</details>
<p><br />
</p>

<h2 id="visualizing-your-training-with-tensorboard">Visualizing your training with Tensorboard</h2>
<p>A useful tool to visualize your training is <a href="https://www.tensorflow.org/tensorboard/"><strong>Tensorboard</strong></a>. You can also have a look at solutions such as <a href="https://wandb.ai/site"><strong>Weights &amp; Biases</strong></a>, but we will focus on the simpler Tensorboard for now.
You can easily use Tensorboard with Pytorch by looking at <a href="https://pytorch.org/docs/stable/tensorboard.html"><strong>torch.utils.tensorboard</strong></a></p>

<h2 id="saving-and-loading-a-pytorch-model">Saving and loading a Pytorch model</h2>
<p>Once training is completed, it can be useful to save the weights of your neural network to use it later. The following <a href="https://pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html">tutorial</a> explains how you can do this. Now, try to save and then load your trained model.</p>

<h2 id="testing-your-model">Testing your model</h2>
<p>You must now <strong>evaluate the performance of your trained model</strong> on the <strong>test set</strong>. To this end, you have to iterate through test samples, and perform forward passes on given data batches. You might want to compute the <strong>test loss</strong>, but also any <strong>accuracy-related metrics</strong> you are interested in. You could also <strong>visualize some test samples</strong> along with the <strong>output distribution of your model</strong>.</p>

<h2 id="comparing-with-other-recurrent-layers">Comparing with other recurrent layers</h2>
<p>In this final part, <strong>replace your custom implementation of a RNN layer with already available layers in Pytorch</strong> such as <a href="https://pytorch.org/docs/stable/generated/torch.nn.RNN.html"><strong>nn.RNN</strong></a>, <a href="https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html"><strong>nn.LSTM</strong></a> or <a href="https://pytorch.org/docs/stable/generated/torch.nn.GRU.html"><strong>nn.GRU</strong></a>. Which ones works best, and does the simple nn.RNN work better than your custom recurrent layer?</p>

      </d-article>

      <d-appendix>
        <d-footnote-list></d-footnote-list>
        <d-citation-list></d-citation-list>
      </d-appendix>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2025 Pierre  Marza.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
    
  </div>
</footer>



  </body>

  <d-bibliography src="/assets/bibliography/2018-12-22-distill.bib">
  </d-bibliography>

</html>
